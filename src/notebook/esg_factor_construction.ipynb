{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8740fb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Working directory: /Users/frank/Projects/QuantX/quantx-data-builder\n",
      "âœ… Libraries imported successfully\n",
      "âœ… Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set project root and change working directory\n",
    "project_root = Path.cwd().parent.parent\n",
    "os.chdir(project_root)\n",
    "print(f\"ðŸ“ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "from tiingo import TiingoClient\n",
    "from core.config import Config\n",
    "from market import ESGManager, PriceManager, RiskFreeRateManager\n",
    "from universe import SP500Universe\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e3a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Components initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize components\n",
    "config = Config(str(project_root / \"config/settings.yaml\"))\n",
    "universe = SP500Universe()\n",
    "\n",
    "tiingo = TiingoClient({\n",
    "    'api_key': config.get('fetcher.tiingo.api_key'),\n",
    "    'session': True\n",
    "})\n",
    "\n",
    "price_mgr = PriceManager(tiingo=tiingo, universe=universe)\n",
    "esg_mgr = ESGManager(universe=universe)\n",
    "\n",
    "fred_api_key = config.get('fetcher.fred.api_key')\n",
    "rf_mgr = RiskFreeRateManager(fred_api_key=fred_api_key)\n",
    "\n",
    "print(\"âœ… Components initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21af8d9",
   "metadata": {},
   "source": [
    "## 1. Load ESG Data for Multiple Stocks\n",
    "\n",
    "Load monthly ESG scores for a sample of S&P 500 stocks to demonstrate factor construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ed2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESG data for 20 stocks from 2014-01-01 to 2025-11-11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ESG data found for JPM on us\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m         esg_data_list.append(esg_df)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Combine all ESG data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m esg_panel = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mesg_data_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Align dates to end-of-month\u001b[39;00m\n\u001b[32m     31\u001b[39m esg_panel[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(esg_panel[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/QuantX/quantx-data-builder/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:380\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    378\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/QuantX/quantx-data-builder/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:443\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    441\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    446\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/QuantX/quantx-data-builder/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:505\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    502\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    508\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Define analysis period and sample stocks\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2025-11-11'\n",
    "\n",
    "# Sample of S&P 500 stocks with good ESG data coverage\n",
    "sample_tickers = [\n",
    "    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA',  # Tech\n",
    "    'JPM', 'BAC', 'WFC', 'GS', 'MS',          # Financials\n",
    "    'JNJ', 'UNH', 'PFE', 'ABBV', 'TMO',       # Healthcare\n",
    "    # 'XOM', 'CVX', 'COP', 'SLB', 'EOG',        # Energy\n",
    "    'PG', 'KO', 'PEP', 'WMT', 'COST',         # Consumer\n",
    "    # 'BA', 'CAT', 'GE', 'MMM', 'HON'           # Industrials\n",
    "]\n",
    "\n",
    "print(f\"Loading ESG data for {len(sample_tickers)} stocks from {start_date} to {end_date}...\")\n",
    "\n",
    "# Load ESG data for all tickers\n",
    "esg_data_list = []\n",
    "\n",
    "for ticker in sample_tickers:\n",
    "    esg_df = esg_mgr.load_esg_data(ticker=ticker, start_date=start_date, end_date=end_date)\n",
    "    \n",
    "    if not esg_df.empty and 'ESG Score' in esg_df.columns:\n",
    "        esg_df['ticker'] = ticker\n",
    "        esg_data_list.append(esg_df)\n",
    "\n",
    "# Combine all ESG data\n",
    "esg_panel = pd.concat(esg_data_list, ignore_index=True)\n",
    "\n",
    "# Align dates to end-of-month\n",
    "esg_panel['date'] = pd.to_datetime(esg_panel['date'])\n",
    "esg_panel['date'] = esg_panel['date'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "print(f\"\\nâœ“ Loaded ESG data for {esg_panel['ticker'].nunique()} stocks\")\n",
    "print(f\"  Total observations: {len(esg_panel):,}\")\n",
    "print(f\"  Date range: {esg_panel['date'].min().date()} to {esg_panel['date'].max().date()}\")\n",
    "print(f\"\\nðŸ“Š ESG Score Summary:\")\n",
    "print(esg_panel['ESG Score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f40be",
   "metadata": {},
   "source": [
    "## 2. Construct Cross-Sectional ESG Factors\n",
    "\n",
    "Build ESG factors by ranking and standardizing scores within each month (cross-sectional approach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cross-sectional factors\n",
    "def calculate_cross_sectional_factors(panel_df, score_column='ESG Score'):\n",
    "    \"\"\"\n",
    "    Calculate cross-sectional ESG factors for each date.\n",
    "    \n",
    "    Returns:\n",
    "    - Percentile rank (0-100)\n",
    "    - Z-score (standardized)\n",
    "    - Decile assignment (1-10)\n",
    "    \"\"\"\n",
    "    factors = panel_df.copy()\n",
    "    \n",
    "    # Group by date and calculate cross-sectional metrics\n",
    "    for date in factors['date'].unique():\n",
    "        mask = factors['date'] == date\n",
    "        scores = factors.loc[mask, score_column]\n",
    "        \n",
    "        # Percentile rank (0-100)\n",
    "        factors.loc[mask, f'{score_column}_pctrank'] = scores.rank(pct=True) * 100\n",
    "        \n",
    "        # Z-score (mean=0, std=1)\n",
    "        mean = scores.mean()\n",
    "        std = scores.std()\n",
    "        if std > 0:\n",
    "            factors.loc[mask, f'{score_column}_zscore'] = (scores - mean) / std\n",
    "        else:\n",
    "            factors.loc[mask, f'{score_column}_zscore'] = 0\n",
    "        \n",
    "        # Decile assignment (1=lowest, 10=highest)\n",
    "        factors.loc[mask, f'{score_column}_decile'] = pd.qcut(\n",
    "            scores, q=10, labels=range(1, 11), duplicates='drop'\n",
    "        )\n",
    "    \n",
    "    return factors\n",
    "\n",
    "# Calculate cross-sectional factors for ESG Score and pillars\n",
    "esg_factors = calculate_cross_sectional_factors(esg_panel, 'ESG Score')\n",
    "\n",
    "if 'Environmental Pillar Score' in esg_panel.columns:\n",
    "    esg_factors = calculate_cross_sectional_factors(esg_factors, 'Environmental Pillar Score')\n",
    "    esg_factors = calculate_cross_sectional_factors(esg_factors, 'Social Pillar Score')\n",
    "    esg_factors = calculate_cross_sectional_factors(esg_factors, 'Governance Pillar Score')\n",
    "\n",
    "print(\"âœ“ Cross-sectional factors calculated\")\n",
    "print(f\"\\nSample factors for {esg_factors['date'].min().date()}:\")\n",
    "sample = esg_factors[esg_factors['date'] == esg_factors['date'].min()][\n",
    "    ['ticker', 'ESG Score', 'ESG Score_pctrank', 'ESG Score_zscore', 'ESG Score_decile']\n",
    "].sort_values('ESG Score', ascending=False).head(10)\n",
    "print(sample.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ea77d",
   "metadata": {},
   "source": [
    "## 3. Calculate ESG Momentum (Time-Series Factor)\n",
    "\n",
    "ESG momentum captures the rate of ESG improvement over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ESG momentum (6-month and 12-month changes)\n",
    "esg_factors = esg_factors.sort_values(['ticker', 'date'])\n",
    "\n",
    "for ticker in esg_factors['ticker'].unique():\n",
    "    mask = esg_factors['ticker'] == ticker\n",
    "    \n",
    "    # 6-month momentum (percent change)\n",
    "    esg_factors.loc[mask, 'ESG_momentum_6m'] = (\n",
    "        esg_factors.loc[mask, 'ESG Score'].pct_change(periods=6) * 100\n",
    "    )\n",
    "    \n",
    "    # 12-month momentum\n",
    "    esg_factors.loc[mask, 'ESG_momentum_12m'] = (\n",
    "        esg_factors.loc[mask, 'ESG Score'].pct_change(periods=12) * 100\n",
    "    )\n",
    "    \n",
    "    # ESG trend (linear slope over 12 months)\n",
    "    scores = esg_factors.loc[mask, 'ESG Score'].values\n",
    "    for i in range(12, len(scores)):\n",
    "        window = scores[i-12:i]\n",
    "        if len(window) == 12 and not np.isnan(window).any():\n",
    "            x = np.arange(12)\n",
    "            slope = np.polyfit(x, window, 1)[0]\n",
    "            esg_factors.loc[mask, 'ESG_trend_12m'] = np.nan\n",
    "            esg_factors.loc[esg_factors[mask].index[i], 'ESG_trend_12m'] = slope\n",
    "\n",
    "print(\"âœ“ ESG momentum factors calculated\")\n",
    "print(f\"\\nESG Momentum Statistics (12-month):\")\n",
    "print(esg_factors['ESG_momentum_12m'].describe())\n",
    "\n",
    "# Show top ESG improvers (latest month)\n",
    "latest_date = esg_factors['date'].max()\n",
    "improvers = esg_factors[esg_factors['date'] == latest_date][\n",
    "    ['ticker', 'ESG Score', 'ESG_momentum_6m', 'ESG_momentum_12m']\n",
    "].dropna().sort_values('ESG_momentum_12m', ascending=False).head(10)\n",
    "\n",
    "print(f\"\\nTop 10 ESG Improvers (12-month, as of {latest_date.date()}):\")\n",
    "print(improvers.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9f53e",
   "metadata": {},
   "source": [
    "## 4. Build Composite ESG Factors\n",
    "\n",
    "Combine multiple dimensions into composite factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite Factor 1: Quality-adjusted ESG (Level + Momentum)\n",
    "# Stocks with high ESG scores AND improving ESG\n",
    "esg_factors['ESG_quality_momentum'] = (\n",
    "    esg_factors['ESG Score_zscore'] + \n",
    "    esg_factors['ESG_momentum_12m'].fillna(0) / 10  # Scale momentum\n",
    ") / 2\n",
    "\n",
    "# Composite Factor 2: Pillar-weighted composite (if pillar data available)\n",
    "if 'Environmental Pillar Score_zscore' in esg_factors.columns:\n",
    "    esg_factors['ESG_composite'] = (\n",
    "        0.4 * esg_factors['Environmental Pillar Score_zscore'] +\n",
    "        0.3 * esg_factors['Social Pillar Score_zscore'] +\n",
    "        0.3 * esg_factors['Governance Pillar Score_zscore']\n",
    "    )\n",
    "\n",
    "# Recalculate cross-sectional ranks for composite factors\n",
    "esg_factors = calculate_cross_sectional_factors(esg_factors, 'ESG_quality_momentum')\n",
    "\n",
    "print(\"âœ“ Composite ESG factors constructed\")\n",
    "print(f\"\\nComposite Factor Distribution (latest month):\")\n",
    "latest = esg_factors[esg_factors['date'] == latest_date]\n",
    "print(latest['ESG_quality_momentum'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd38a8",
   "metadata": {},
   "source": [
    "## 5. Visualize Factor Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec82170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: ESG Score distribution over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ESG Score time series (median and quartiles)\n",
    "monthly_stats = esg_factors.groupby('date')['ESG Score'].agg(['mean', 'median', \n",
    "                                                                lambda x: x.quantile(0.25),\n",
    "                                                                lambda x: x.quantile(0.75)])\n",
    "monthly_stats.columns = ['Mean', 'Median', 'Q25', 'Q75']\n",
    "\n",
    "axes[0, 0].plot(monthly_stats.index, monthly_stats['Median'], label='Median', linewidth=2)\n",
    "axes[0, 0].fill_between(monthly_stats.index, monthly_stats['Q25'], monthly_stats['Q75'], \n",
    "                         alpha=0.3, label='IQR')\n",
    "axes[0, 0].set_title('ESG Score Distribution Over Time')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('ESG Score')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ESG Score histogram (latest month)\n",
    "axes[0, 1].hist(latest['ESG Score'].dropna(), bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title(f'ESG Score Distribution ({latest_date.date()})')\n",
    "axes[0, 1].set_xlabel('ESG Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# ESG Momentum distribution\n",
    "axes[1, 0].hist(esg_factors['ESG_momentum_12m'].dropna(), bins=30, \n",
    "                edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1, 0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_title('ESG Momentum Distribution (12-month)')\n",
    "axes[1, 0].set_xlabel('ESG Change (%)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Z-score distribution (should be ~N(0,1) each month)\n",
    "axes[1, 1].hist(latest['ESG Score_zscore'].dropna(), bins=20, \n",
    "                edgecolor='black', alpha=0.7, color='purple')\n",
    "axes[1, 1].set_title(f'ESG Z-Score Distribution ({latest_date.date()})')\n",
    "axes[1, 1].set_xlabel('Z-Score')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Factor distributions visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488c5e0",
   "metadata": {},
   "source": [
    "## 6. Calculate Factor Returns (Long-Short Portfolios)\n",
    "\n",
    "Test if ESG factors predict returns by creating long-short portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load monthly returns for the sample stocks\n",
    "print(\"Loading monthly returns for factor analysis...\")\n",
    "\n",
    "returns_list = []\n",
    "for ticker in sample_tickers:\n",
    "    price_data = price_mgr.load_price_data(\n",
    "        symbol=ticker,\n",
    "        frequency='monthly',\n",
    "        start_date=start_date,\n",
    "        end_date=end_date\n",
    "    )\n",
    "    \n",
    "    if price_data is not None and len(price_data) > 0:\n",
    "        price_data['ticker'] = ticker\n",
    "        price_data['date'] = pd.to_datetime(price_data['date'])\n",
    "        price_data['date'] = price_data['date'] + pd.offsets.MonthEnd(0)\n",
    "        \n",
    "        # Calculate returns\n",
    "        price_data = price_data.sort_values('date')\n",
    "        price_data['return'] = price_data['adj_close'].pct_change()\n",
    "        \n",
    "        returns_list.append(price_data[['ticker', 'date', 'return']])\n",
    "\n",
    "returns_panel = pd.concat(returns_list, ignore_index=True)\n",
    "\n",
    "print(f\"âœ“ Loaded returns for {returns_panel['ticker'].nunique()} stocks\")\n",
    "print(f\"  Total observations: {len(returns_panel):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb5dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ESG factors with forward returns\n",
    "# Key: Use ESG factor at time t to predict return from t to t+1\n",
    "\n",
    "factor_returns = esg_factors.merge(\n",
    "    returns_panel[['ticker', 'date', 'return']], \n",
    "    on=['ticker', 'date'], \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Shift returns forward (return in month t+1 given factor in month t)\n",
    "factor_returns = factor_returns.sort_values(['ticker', 'date'])\n",
    "factor_returns['forward_return'] = factor_returns.groupby('ticker')['return'].shift(-1)\n",
    "\n",
    "# Drop rows with missing forward returns or factors\n",
    "analysis_df = factor_returns.dropna(subset=['forward_return', 'ESG Score_zscore'])\n",
    "\n",
    "print(f\"âœ“ Merged factors with forward returns\")\n",
    "print(f\"  Analysis observations: {len(analysis_df):,}\")\n",
    "print(f\"  Date range: {analysis_df['date'].min().date()} to {analysis_df['date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate long-short portfolio returns based on ESG deciles\n",
    "portfolio_returns = []\n",
    "\n",
    "for date in analysis_df['date'].unique():\n",
    "    month_data = analysis_df[analysis_df['date'] == date].copy()\n",
    "    \n",
    "    if len(month_data) < 10:  # Need enough stocks for deciles\n",
    "        continue\n",
    "    \n",
    "    # Assign deciles based on ESG z-score\n",
    "    month_data['decile'] = pd.qcut(month_data['ESG Score_zscore'], \n",
    "                                    q=10, labels=range(1, 11), duplicates='drop')\n",
    "    \n",
    "    # Calculate equal-weighted returns for each decile\n",
    "    decile_returns = month_data.groupby('decile')['forward_return'].mean()\n",
    "    \n",
    "    if 1 in decile_returns.index and 10 in decile_returns.index:\n",
    "        # Long-short: Long top decile, short bottom decile\n",
    "        long_short = decile_returns[10] - decile_returns[1]\n",
    "        \n",
    "        portfolio_returns.append({\n",
    "            'date': date,\n",
    "            'long_return': decile_returns[10],\n",
    "            'short_return': decile_returns[1],\n",
    "            'long_short_return': long_short,\n",
    "            'decile_1': decile_returns[1],\n",
    "            'decile_10': decile_returns[10]\n",
    "        })\n",
    "\n",
    "portfolio_df = pd.DataFrame(portfolio_returns)\n",
    "\n",
    "print(f\"âœ“ Calculated long-short portfolio returns\")\n",
    "print(f\"\\nLong-Short Portfolio Statistics:\")\n",
    "print(f\"  Mean monthly return: {portfolio_df['long_short_return'].mean()*100:.2f}%\")\n",
    "print(f\"  Std dev: {portfolio_df['long_short_return'].std()*100:.2f}%\")\n",
    "print(f\"  Sharpe (annualized): {portfolio_df['long_short_return'].mean() / portfolio_df['long_short_return'].std() * np.sqrt(12):.2f}\")\n",
    "print(f\"  Win rate: {(portfolio_df['long_short_return'] > 0).mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee35fcf",
   "metadata": {},
   "source": [
    "## 7. Visualize Factor Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23598aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns of long-short ESG factor\n",
    "portfolio_df = portfolio_df.sort_values('date')\n",
    "portfolio_df['cumulative_return'] = (1 + portfolio_df['long_short_return']).cumprod()\n",
    "portfolio_df['long_cumulative'] = (1 + portfolio_df['long_return']).cumprod()\n",
    "portfolio_df['short_cumulative'] = (1 + portfolio_df['short_return']).cumprod()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Cumulative returns\n",
    "axes[0].plot(portfolio_df['date'], portfolio_df['cumulative_return'], \n",
    "             label='Long-Short (D10-D1)', linewidth=2, color='blue')\n",
    "axes[0].plot(portfolio_df['date'], portfolio_df['long_cumulative'], \n",
    "             label='Long (D10)', linewidth=1.5, alpha=0.7, color='green')\n",
    "axes[0].plot(portfolio_df['date'], portfolio_df['short_cumulative'], \n",
    "             label='Short (D1)', linewidth=1.5, alpha=0.7, color='red')\n",
    "axes[0].axhline(1, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0].set_title('ESG Factor Portfolio Performance (High ESG - Low ESG)')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cumulative Return')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly returns distribution\n",
    "axes[1].bar(portfolio_df['date'], portfolio_df['long_short_return'] * 100, \n",
    "            color=['green' if x > 0 else 'red' for x in portfolio_df['long_short_return']])\n",
    "axes[1].axhline(0, color='black', linestyle='-', linewidth=1)\n",
    "axes[1].set_title('Monthly Long-Short Returns')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Return (%)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Factor performance visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98212af1",
   "metadata": {},
   "source": [
    "## 8. Factor Correlation Analysis\n",
    "\n",
    "Analyze correlations between ESG factors and test orthogonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f74891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix of factors\n",
    "factor_cols = [\n",
    "    'ESG Score_zscore',\n",
    "    'ESG_momentum_12m',\n",
    "    'ESG_quality_momentum'\n",
    "]\n",
    "\n",
    "if 'Environmental Pillar Score_zscore' in esg_factors.columns:\n",
    "    factor_cols.extend([\n",
    "        'Environmental Pillar Score_zscore',\n",
    "        'Social Pillar Score_zscore',\n",
    "        'Governance Pillar Score_zscore'\n",
    "    ])\n",
    "\n",
    "correlation_df = analysis_df[factor_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_df, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "            center=0, vmin=-1, vmax=1, square=True)\n",
    "plt.title('ESG Factor Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Factor correlations analyzed\")\n",
    "print(\"\\nKey Observations:\")\n",
    "print(f\"  ESG Level vs Momentum: r = {correlation_df.loc['ESG Score_zscore', 'ESG_momentum_12m']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9bc0a3",
   "metadata": {},
   "source": [
    "## 9. Save ESG Factors for Further Analysis\n",
    "\n",
    "Export constructed factors for use in other analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53977034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save factor data\n",
    "output_dir = Path(\"data/results/esg_factors\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = output_dir / f\"esg_factors_{start_date}_{end_date}.parquet\"\n",
    "esg_factors.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"âœ“ ESG factors saved to: {output_file}\")\n",
    "print(f\"\\nFactor columns created:\")\n",
    "for col in esg_factors.columns:\n",
    "    if any(x in col for x in ['_zscore', '_pctrank', '_decile', '_momentum', '_composite']):\n",
    "        print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179ba2e",
   "metadata": {},
   "source": [
    "## Summary: ESG Factor Construction\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. **Cross-Sectional Factors**: \n",
    "   - ESG scores normalized within each month\n",
    "   - Z-scores provide standardized exposure\n",
    "   - Deciles enable portfolio construction\n",
    "\n",
    "2. **Momentum Factors**:\n",
    "   - ESG improvement measured over 6 and 12 months\n",
    "   - Captures time-series variation in ESG quality\n",
    "   - Can identify improving vs deteriorating companies\n",
    "\n",
    "3. **Factor Performance**:\n",
    "   - Long-short ESG factor shows [positive/negative] returns\n",
    "   - Sharpe ratio indicates [strong/weak] risk-adjusted performance\n",
    "   - Win rate of [X]% suggests [consistent/inconsistent] alpha\n",
    "\n",
    "4. **Factor Independence**:\n",
    "   - ESG level and momentum show [low/moderate/high] correlation\n",
    "   - E, S, G pillars provide [diversified/overlapping] signals\n",
    "   - Composite factors capture multiple dimensions\n",
    "\n",
    "**Next Steps**:\n",
    "- Integrate ESG factors into multi-factor models\n",
    "- Test factor timing strategies\n",
    "- Analyze sector-specific ESG effects\n",
    "- Combine with traditional factors (value, momentum, quality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
